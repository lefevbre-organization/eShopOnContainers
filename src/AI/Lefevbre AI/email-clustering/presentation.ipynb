{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<div style=\"float: left;\">![lefebvre-147x30.png](attachment:lefebvre-147x30.png)</div>\n\n",
      "attachments": {
        "lefebvre-147x30.png": {
          "image/png": "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"
        }
      }
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "notes"
        }
      },
      "cell_type": "markdown",
      "source": "#  <font color=#001978>Used machine learning to classify emails and turn them into insights</font>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### <font color=#001978>COMPREHEND - Ability to read and understand incoming emails</font>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Alberto Valverde Escribano.\n# Software engineer and R&D Robotics.\n# Code used machine learning to classify emails and turn them into insights.\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans, MiniBatchKMeans\nfrom helpers import *\n\nemails = pd.read_csv('alberto-valverde-gmail.csv')\nemails = emails.head(10)\n\n# Lets create a new frame with the data we need.\nemail_df = pd.DataFrame(parse_into_emails(emails.message))\n\n# Drop emails with empty body, to or from_ columns.\nemail_df.drop(email_df.query(\"body == '' | to == '' | from_ == ''\").index, inplace=True)\nstopwords = ENGLISH_STOP_WORDS.union(['ect', 'hou', 'com', 'recipient'])\nvect = TfidfVectorizer(analyzer='word', stop_words=stopwords, max_df=0.3, min_df=2)\n\nX = vect.fit_transform(email_df.body)\nfeatures = vect.get_feature_names()\n\n# Now we print the top terms across all documents.\nprint (top_mean_feats(X, features, None, 0.1, 10))\n\n# As clustering algorithm KMeams is a perfect fit.\nn_clusters = 3\nclf = KMeans(n_clusters=n_clusters,\n            max_iter=100,\n            init='k-means++',\n            n_init=1)\nlabels = clf.fit_predict(X)\n\n# For larger datasets use mini-batch KMeans, so we dont have to read all data into memory.\n# batch_size = 500\n# clf = MiniBatchKMeans(n_clusters=n_clusters, init_size=1000, batch_size=batch_size, max_iter=100)\n# clf.fit(X)\n\n# Let's plot this with matplotlib to visualize it.\n# First we need to make 2D coordinates from the sparse matrix.\nX_dense = X.todense()\npca = PCA(n_components=2).fit(X_dense)\ncoords = pca.transform(X_dense)\n\n# Lets plot it again, but this time we add some color to it.\n# This array needs to be at least the length of the n_clusters.\nlabel_colors = [\"#2AB0E9\", \"#2BAF74\", \"#D7665E\", \"#CCCCCC\",\n                \"#D2CA0D\", \"#522A64\", \"#A3DB05\", \"#FC6514\"]\ncolors = [label_colors[i] for i in labels]\n\nplt.scatter(coords[:, 0], coords[:, 1], c=colors)\n# Plot the cluster centers\ncentroids = clf.cluster_centers_\ncentroid_coords = pca.transform(centroids)\nplt.scatter(centroid_coords[:, 0], centroid_coords[:, 1], marker='X', s=200, linewidths=2, c='#444d60')\nplt.show()\n\n#Use this to print the top terms per cluster with matplotlib.\nplot_tfidf_classfeats_h(top_feats_per_cluster(X, labels, features, 0.1, 25))\n\n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "          features     score\n0               di  0.122152\n1            robot  0.094398\n2               19  0.079114\n3  oregonstateuniv  0.076505\n4               22  0.074687\n5    3dgnbpdpelg4w  0.066675\n6           forbes  0.066675\n7               06  0.066483\n8        raspberry  0.064786\n9               pi  0.064786\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x900 with 3 Axes>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### <font color=#001978>Comprehing single messages from Inbox</font>\nReturning the top terms out of a specific email."
    },
    {
      "metadata": {
        "trusted": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "code",
      "source": "# Alberto Valverde Escribano.\n# Software engineer and R&D Robotics.\n# Code used machine learning to classify specific email and turn them into insights.\n\nimport numpy as np\nimport pandas as pd\n#import matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans, MiniBatchKMeans\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import TruncatedSVD \nfrom sklearn.preprocessing import normalize \n\nfrom helpers import * \n\nemails = pd.read_csv('split_emails.csv')\nemails = emails.head(4000)\n# Lets create a new frame with the data we need.\nemail_df = pd.DataFrame(parse_into_emails(emails.message))\n\n# Drop emails with empty body, to or from_ columns. \nemail_df.drop(email_df.query(\"body == '' | to == '' | from_ == ''\").index, inplace=True)\nprint (email_df.head(9))\n\n# After running this function, I created a new dataframe that looks like this:\n",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "                                                 body  \\\n0   Buenos días, llamé el 24 de abril a Intrum por...   \n1   Hola buenas resulta que el día 27/07/2016 Iba ...   \n2   Hola, me llamo Ramón. Estoy divorciado desde f...   \n3   Randy,Can you send me a schedule of the salary...   \n5   Greg,How about either next Tuesday or Thursday...   \n6   Phillip Allen (pallen@enron.com)Mike Grigsby (...   \n8   I don't think these are required by the ISP2. ...   \n9   ---------------------- Forwarded by Phillip K ...   \n10  Mr. Buckner,For delivered gas behind San Diego...   \n\n                                                  to                    from_  \n0                               tim.belden@enron.com  phillip.allen@enron.com  \n1                            john.lavorato@enron.com  phillip.allen@enron.com  \n2                             leah.arsdall@enron.com  phillip.allen@enron.com  \n3                              randall.gay@enron.com  phillip.allen@enron.com  \n5                               greg.piper@enron.com  phillip.allen@enron.com  \n6   david.l.johnson@enron.com, john.shafer@enron.com  phillip.allen@enron.com  \n8                               mark.scott@enron.com  phillip.allen@enron.com  \n9            \"'Pallen@Enron.com'\" <Pallen@Enron.com>  phillip.allen@enron.com  \n10                        buck.buckner@honeywell.com  phillip.allen@enron.com  \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "### <font color=#001978>MACHINE LEARNING</font>\nTransform de dataframes (from emails raw message) into workable text and extract the features"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "# At this point we are going to tokenize the bodies and convert them\n# into a document-term matrix.\n\n# Some note on min_df and max_df\n# max_df=0.5 means \"ignore all terms that appear in more then 50% of the documents\"\n# min_df=2 means \"ignore all terms that appear in less then 2 documents\"\nstopwords = ENGLISH_STOP_WORDS.union(['que', 'el', 'una', 'ha' , \"la\", 'por', \"lo\" , \"es\", \"los\" , \"al\", \"en\", \"mi\", \"es\", \"del\",'para', 'hacer', 'tengo' , \"pero\"])\nvect = TfidfVectorizer(analyzer='word', stop_words=stopwords, max_df=0.3, min_df=1)\n\nX = vect.fit_transform(email_df.body)\nfeatures = vect.get_feature_names()\n\n# The procesing message\nmsg_num = 0\n\n# Saving Feature date for future Natural Language Processing\nFeatureDataFramesForAI = top_feats_in_doc(X, features, msg_num, 10)\n\n# Let's print the top 10 terms in document 1\nprint (FeatureDataFramesForAI)\n\n# After running this function on a document, it came up with the following result.",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "        features     score\n0          dicho  0.286853\n1          deuda  0.286853\n2           pago  0.286853\n3           años  0.191235\n4  documentación  0.191235\n5          ahora  0.191235\n6           días  0.191235\n7          debía  0.095618\n8            dni  0.095618\n9          estos  0.095618\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### <font color=#001978> All making sense if you look into the corresponding email:</font>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print (emails.message[msg_num])",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\nDate: Mon, 14 May 2001 16:39:00 -0700 (PDT)\nFrom: phillip.allen@enron.com\nTo: tim.belden@enron.com\nSubject: \nMime-Version: 1.0\nContent-Type: text/plain; charset=us-ascii\nContent-Transfer-Encoding: 7bit\nX-From: Phillip K Allen\nX-To: Tim Belden <Tim Belden/Enron@EnronXGate>\nX-cc: \nX-bcc: \nX-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\nX-Origin: Allen-P\nX-FileName: pallen (Non-Privileged).pst\n\nBuenos días, llamé el 24 de abril a Intrum por una deuda que ya cancelé por un asunto con la Caixa \ny al darles mi DNI resulta que me dice que tengo una deuda de 180 euros con Orange desde el 2007 \nde la que yo no tenía constancia, no tengo ni idea si debía o no porque han pasado muchos años y \nno recuerdo pero no he recibido en todos estos años documentación de dicha deuda de ningún tipo ya \nque de ser así la hubiera pagado, me ha dicho que mandaron documentación a una dirección donde \nvivía en 2007, hoy me ha vuelto a llamar bastante borde para que haga el pago ahora con tarjeta \ny le he dicho que primero quiero saber de qué es eso y me ha dicho que solicite las facturas\n y que en 3 días me llamará para hacer el pago pero me ha amenazado con llevarlo ahora vía judicial\n si no hacía el pago y que me costaría el doble, ¿que debo hacer?\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install --upgrade azure-cognitiveservices-language-textanalytics",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already up-to-date: azure-cognitiveservices-language-textanalytics in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (0.2.0)\nRequirement already satisfied, skipping upgrade: azure-common~=1.1 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from azure-cognitiveservices-language-textanalytics) (1.1.23)\nRequirement already satisfied, skipping upgrade: msrest>=0.5.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from azure-cognitiveservices-language-textanalytics) (0.6.9)\nRequirement already satisfied, skipping upgrade: isodate>=0.6.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (0.6.0)\nRequirement already satisfied, skipping upgrade: requests~=2.16 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (2.22.0)\nRequirement already satisfied, skipping upgrade: requests-oauthlib>=0.5.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (1.2.0)\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (2018.10.15)\nRequirement already satisfied, skipping upgrade: six in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (1.11.0)\nRequirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (1.23)\nRequirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (2.7)\nRequirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (3.0.4)\nRequirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (3.1.0)\n\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\nfrom msrest.authentication import CognitiveServicesCredentials\n\nimport os\n\nkey_var_name = '855b09a467dd4d328e0fb84aaa15c8f3'\n\nsubscription_key = key_var_name\n\nendpoint_var_name = 'https://analisislefebvre.cognitiveservices.azure.com/'\n\nendpoint = endpoint_var_name\n\ncredentials = CognitiveServicesCredentials(subscription_key)\n\ntext_analytics = TextAnalyticsClient(endpoint_var_name, credentials=credentials)\n\ndocuments = [\n    {\n        \"id\": \"1\",\n        \"language\": \"es\",\n        \"text\": emails.message[msg_num]\n    }\n]\nresponse = text_analytics.sentiment(documents=documents)\nfor document in response.documents:\n    print(\"Document Id: \", document.id, \", Sentiment Score: \",\n          \"{:.2f}\".format(document.score))\n    empaticValue = \"{:.2f}\".format(document.score)\n    if float(empaticValue) > 0.5:\n       empaticValueStr= \"Satisfied\"\n    if float(empaticValue) < 0.5:\n       empaticValueStr= \"unsatisfied\"\n    if float(empaticValue) >= 1 :\n       empaticValueStr= \"happy\"\nprint  (empaticValueStr)     \n    ",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Document Id:  1 , Sentiment Score:  0.45\nunsatisfied\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "\n### <font color=#001978>(NPL) NATURAL LANGUAGE PROCESSING</font>\n####  Required follow-up actions based on its understanding of the email/s"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install pyspellchecker",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already satisfied: pyspellchecker in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (0.5.2)\n\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install dialogflow",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting dialogflow\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/db/1e71dd7c5c748b1a03e679b8890550ddeff8b21b58a76b92eb5a7beff02a/dialogflow-0.7.2-py2.py3-none-any.whl (310kB)\n\u001b[K     |████████████████████████████████| 317kB 299kB/s eta 0:00:01     |████████████▋                   | 122kB 299kB/s eta 0:00:01\n\u001b[?25hCollecting google-api-core[grpc]<2.0.0dev,>=1.14.0 (from dialogflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/3a/c528ef37f48d6ffba16f0f3c0426456ba21e0dd32be9c61a2ade93e07faa/google_api_core-1.14.3-py2.py3-none-any.whl (68kB)\n\u001b[K     |████████████████████████████████| 71kB 2.5MB/s eta 0:00:011\n\u001b[?25hCollecting google-auth<2.0dev,>=0.4.0 (from google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/9b/ed0516cc1f7609fb0217e3057ff4f0f9f3e3ce79a369c6af4a6c5ca25664/google_auth-1.6.3-py2.py3-none-any.whl (73kB)\n\u001b[K     |████████████████████████████████| 81kB 3.4MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (2.22.0)\nRequirement already satisfied: pytz in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (2018.7)\nRequirement already satisfied: setuptools>=34.0.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (41.1.0)\nCollecting googleapis-common-protos<2.0dev,>=1.6.0 (from google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow)\n  Downloading https://files.pythonhosted.org/packages/eb/ee/e59e74ecac678a14d6abefb9054f0bbcb318a6452a30df3776f133886d7d/googleapis-common-protos-1.6.0.tar.gz\nRequirement already satisfied: protobuf>=3.4.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (3.9.1)\nRequirement already satisfied: six>=1.10.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (1.11.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (1.23.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (0.2.2)\nCollecting rsa>=3.1.4 (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow)\n  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\nCollecting cachetools>=2.0.0 (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow)\n  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\nRequirement already satisfied: certifi>=2017.4.17 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (2018.10.15)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (1.23)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (3.0.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (2.7)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (0.4.4)\nBuilding wheels for collected packages: googleapis-common-protos\n  Building wheel for googleapis-common-protos (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for googleapis-common-protos: filename=googleapis_common_protos-1.6.0-cp36-none-any.whl size=74511 sha256=120a7f9c419be45c227e451c0ff0d4d5af502e60cf318504a0fd80df5e295efe\n  Stored in directory: /home/nbuser/.cache/pip/wheels/9e/3d/a2/1bec8bb7db80ab3216dbc33092bb7ccd0debfb8ba42b5668d5\nSuccessfully built googleapis-common-protos\nInstalling collected packages: rsa, cachetools, google-auth, googleapis-common-protos, google-api-core, dialogflow\nSuccessfully installed cachetools-3.1.1 dialogflow-0.7.2 google-api-core-1.14.3 google-auth-1.6.3 googleapis-common-protos-1.6.0 rsa-4.0\n\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# Alberto Valverde Escribano.\n# Software engineer and R&D Robotics.\n# Code used Natural Langueage Processing to gives the ability to read, understand and derive meaning from email´s features result.\n\nimport dialogflow\nfrom google.api_core.exceptions import InvalidArgument\nfrom SpellCorrector import *\n\nimport os\nfrom google.oauth2 import service_account\n\n# Attributes\nDIALOGFLOW_PROJECT_ID = 'lefebvre-ivivrs'\nDIALOGFLOW_LANGUAGE_CODE = 'en-ES'\nGOOGLE_APPLICATION_CREDENTIALS = 'lefebvre-ivivrs-c18aa8f99956.json'\nSESSION_ID = '115760287604807540329'\n\ncredentials = service_account.Credentials.from_service_account_file(\"lefebvre-ivivrs-c18aa8f99956.json\")\nscoped_credentials = credentials.with_scopes(['https://www.googleapis.com/auth/cloud-platform'])\n\n# Correcting the spelling\n# correctedPhrase = getSpellCorrectedPhrase(phrase)\n\n    \nvalues= \"\"\nfor index, row in FeatureDataFramesForAI.iterrows():\n    #print(row['features'])\n    values= values + \" \" + row['features']   \n    \ncorrectedPhrase = values\n\n# Initializing a client\nsession_client = dialogflow.SessionsClient(credentials=credentials)\n\nsession = session_client.session_path(DIALOGFLOW_PROJECT_ID, SESSION_ID)\n\ntext_input = dialogflow.types.TextInput(text=correctedPhrase, language_code=DIALOGFLOW_LANGUAGE_CODE)\n\nquery_input = dialogflow.types.QueryInput(text=text_input)\n\ntry:\n    response = session_client.detect_intent(session=session, query_input=query_input)\nexcept InvalidArgument:\n    raise\n\nprint(\"Query text:\", response.query_result.query_text)\nprint(\"Detected intent:\", response.query_result.intent.display_name)\nprint(\"Detected intent confidence:\", response.query_result.intent_detection_confidence)\nprint(\"Response:\", response.query_result.fulfillment_text)\n    \n#saving value for next RabbitMQ event\nMyRabbitmqMessage = \"Se detecta un evento relacionado con \" + response.query_result.fulfillment_text + \".\" + \" Entidad \" + response.query_result.intent.display_name + \"el cliente parece sentirse: \" + empaticValueStr \nprint (\"Empatic: \" + empaticValueStr) ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Query text: dicho deuda pago años documentación ahora días debía dni estos\nDetected intent: Abogados de derecho mercantil y derecho concursal\nDetected intent confidence: 0.8566814661026001\nResponse: Derecho Concursal, Insolvencias y Concurso de Acreedores\nEmpatic: unsatisfied\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install googletrans",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting googletrans\n  Downloading https://files.pythonhosted.org/packages/fd/f0/a22d41d3846d1f46a4f20086141e0428ccc9c6d644aacbfd30990cf46886/googletrans-2.4.0.tar.gz\nRequirement already satisfied: requests in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from googletrans) (2.22.0)\nRequirement already satisfied: certifi>=2017.4.17 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests->googletrans) (2018.10.15)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests->googletrans) (1.23)\nRequirement already satisfied: idna<2.9,>=2.5 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests->googletrans) (2.7)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests->googletrans) (3.0.4)\nBuilding wheels for collected packages: googletrans\n  Building wheel for googletrans (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for googletrans: filename=googletrans-2.4.0-cp36-none-any.whl size=20593 sha256=75d73a0b5ec4632d70995a32a5823844aff78c428593d350a137141093ed79a5\n  Stored in directory: /home/nbuser/.cache/pip/wheels/50/d6/e7/a8efd5f2427d5eb258070048718fa56ee5ac57fd6f53505f95\nSuccessfully built googletrans\nInstalling collected packages: googletrans\nSuccessfully installed googletrans-2.4.0\n\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Alberto Valverde Escribano.\n# Software engineer and R&D Robotics.\n# Code used googletrans to translate the result to english.\n\nfrom googletrans import Translator\n\nT = Translator()\n\ntry:\n  MyRabbitmqMessage = T.translate(MyRabbitmqMessage,src='es',dest='en').text\n  print(MyRabbitmqMessage)\nexcept:\n  print ('translation Error!!!')",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "an event related to Bankruptcy Law, Insolvency and Creditors Contest is detected. Lawyers entity client concursalel commercial law and law seems to feel: Unsatisfied\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install pika",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting pika\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/ae/8bedf0e9f1c0c5d046db3a7428a4227fe36ec1b8e25607f3c38ac9bf513c/pika-1.1.0-py2.py3-none-any.whl (148kB)\n\u001b[K     |████████████████████████████████| 153kB 3.2MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: pika\nSuccessfully installed pika-1.1.0\n\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# Alberto Valverde Escribano.\n# Software engineer and R&D Robotics.\n# Code used pika to sends messages to the \"email-clustering\" queue.\n\nimport pika\n\ncredentials = pika.PlainCredentials('test', 'test')\nconnection = pika.BlockingConnection(\n    pika.ConnectionParameters(host='lefebvre.westeurope.cloudapp.azure.com', credentials=credentials))\nchannel = connection.channel()\n\nchannel.queue_declare(queue='email-clustering')\n\nchannel.basic_publish(exchange='', routing_key='email-clustering', body=MyRabbitmqMessage)\nprint(\" [x] Sent \" + MyRabbitmqMessage)\nprint(\"Event was sended successful\")\nconnection.close()",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": " [x] Sent an event related to Bankruptcy Law, Insolvency and Creditors Contest is detected. Lawyers entity client concursalel commercial law and law seems to feel: Unsatisfied\nEvent was sended successful\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "celltoolbar": "Raw Cell Format",
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}